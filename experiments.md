# 도메인 분류 실험 기록

## 실험 1: 도메인 정의 및 의도 기반 분류 (Stage 1)
- **날짜**: 2025-12-20
- **가설**: 도메인별 상세 정의와 예시를 제공하면 분류 정확도가 향상될 것이다.
- **결과**:
  - 정확도: 48% → 73% (100개 샘플 기준)
- **분석**:
  - 긍정적: 상세 정의 추가로 기본적인 분류 성능 확보.
  - 문제점: "보험금 보장"을 "제지급"으로 오분류하는 경향 심함 (질문의 의도 vs 문서의 내용 혼동).

---

## 실험 2: RAG 문서 카테고리 관점 적용 (Stage 2)
- **날짜**: 2025-12-20
- **가설**: 프롬프트의 역할을 "질문의 의도 분류"에서 "답변을 찾을 문서 카테고리 선택"으로 재정의하면 RAG 시스템에 적합한 분류가 가능할 것이다.
- **결과**:
  - 정확도: 73% → 78% (100개 샘플 기준)
  - 주요 개선: 보험금 보장 ↔ 제지급 혼동 81% 감소.
- **분석**:
  - 긍정적: "청구 서류" 질문을 "보장 조건 문서(보험금 보장)"로 올바르게 연결하기 시작함.
  - 부정적: 제지급 도메인의 정의가 좁아지며 정확도가 일부 하락함.

---

## 실험 3: 전체 데이터셋 전수 테스트 (Baseline)
- **날짜**: 2025-12-20
- **목적**: 100개 샘플에 최적화된 프롬프트의 전체 데이터셋(695개)에 대한 일반화 성능 검증.
- **결과**:
  - **전체 정확도**: 63.60% (442/695)
    - 100개 샘플(78%) 대비 약 14.4%p 하락 (과적합 확인).
  - **도메인별 정확도**:
    - **우수**: 분리보관(100%), 헬스케어서비스(91.67%), 해피콜(88.89%), 대출(81.25%)
    - **저조**: 민원(14.29%), 채널 표기 코드(34.48%), 보험료납입(46.38%), 제지급(50.52%)
- **분석 (주요 실패 원인)**:
  1.  **샘플 편향**: 100개 샘플에 포함되지 않았던 도메인(채널 표기 코드, 신계약 미결 등)의 정의가 부실했음.
  2.  **주요 혼동 패턴 (Top 5)**:
      - **보험료납입 ↔ 계약정보 (17건)**: "납입중지", "일시납입중지" 등이 계약정보로 오분류됨.
      - **제지급 ↔ 계약해지 (15건)**: "청약철회", "해지환급금" 관련 질문이 제지급 절차로 오분류됨.
      - **계약정보 ↔ 보험료납입 (14건)**: "부활 보험료" 납입 관련이 보험료납입으로 오분류됨.
      - **계약정보 ↔ 증명서 안내장 (13건)**: "증권 재발행" 등이 계약정보 확인으로 오분류됨.
      - **민원 ↔ 계약해지 (9건)**: "위법계약 해지", "품질보증 해지"가 민원이 아닌 계약해지로 오분류됨.

---

## 실험 4: 도메인 정의 상세화 및 키워드 보강
- **날짜**: 2025-12-20
- **가설**: 전수 테스트에서 식별된 오분류 패턴(납입중지, 위법계약, 특정 코드 등)을 반영하여 도메인 정의를 구체화하고, 0% 정확도였던 도메인들의 정의를 보강하면 정확도가 향상될 것이다.
- **변경 사항**:
  1.  **전체 21개 도메인 상세 정의**: 간략하게 정의되었던 도메인들을 모두 상세 포맷(문서 내용, 답변 가능, 답변 불가, 핵심 키워드)으로 확장.
  2.  **특정 혼동 키워드 명시**:
      - **보험료납입**: "납입중지", "일시납입중지" 추가 (계약정보와 구분).
      - **민원**: "위법계약 해지", "품질보증 해지" 추가 (계약해지와 구분).
      - **채널 표기 코드**: "통장 표기(RTB)", "ARS 번호", "AIA05" 예시 추가.
      - **제지급**: "자기관리자금", "중도인출" 추가.
      - **증명서 안내장**: "소득공제 대상 여부 확인" 추가 (법 제도와 구분).
- **결과 (150개 층화 샘플링)**:
  - **정확도**: 69.33% (104/150)
  - **성과**: 9개 도메인(민원, 변액, 분리보관 등) 100% 달성. 전수 테스트(63.6%) 대비 약 5.7%p 향상.
  - **남은 문제**:
    - **제지급 ↔ 계약해지 (5건)**: "청약철회"는 여전히 제지급으로 오분류됨.
    - **법 제도 쏠림 현상**: 세금, 상속 등 법적 용어 등장 시 무조건 법 제도로 분류.
    - **계약정보 ↔ 제지급/보험료납입**: 계약정보의 경계가 여전히 모호함.

---

## 실험 5: Chain-of-Thought (CoT) 및 오분류 패턴 방어
- **날짜**: 2025-12-20
- **가설**: 단순 정의 나열을 넘어, 모델이 단계적으로 추론하도록 유도(CoT)하고, 자주 틀리는 "함정 패턴"을 명시적으로 경고하면 정확도가 80% 이상으로 향상될 것이다.
- **결과 (150개 층화 샘플링)**:
  - **정확도**: 66.00% (99/150) - **실험 4 대비 3.33%p 하락**
- **실패 원인 분석**:
  1.  **과도한 추론**: CoT가 오히려 단순 매칭될 수 있는 키워드를 과해석하게 만듦.
  2.  **복잡성 증가**: 프롬프트가 길어지면서 Negative Constraints가 무시됨.

---

## 실험 6: Rule-based 가이드 및 우선순위 명시 (CoT 제거)
- **날짜**: 2025-12-20
- **가설**: 복잡한 추론(CoT) 대신, 혼동되는 케이스에 대한 **명확한 우선순위 규칙(Rule)**을 제시하고, 실패했던 케이스를 **Few-shot 예시**로 직접 학습시키면 정확도가 회복될 것이다.
- **결과 (150개 층화 샘플링)**:
  - **정확도**: 57.33% (86/150) - **최저 기록 갱신 ⚠️**
- **실패 원인 분석**:
  1.  **규칙의 경직성**: "이건 이거다" 식의 규칙 나열이 LLM의 유연한 판단을 방해함.
  2.  **프롬프트 과부하**: 많은 규칙이 오히려 핵심 도메인 정의에 대한 집중력을 떨어뜨림.

---

## 실험 7: In-Context Query Rewriting (질문 재정의)
- **날짜**: 2025-12-20
- **가설**: 사용자의 모호한 질문(구어체)을 **"표준화된 보험 업무 용어"**로 먼저 재작성(Rewriting)하게 한 뒤 도메인을 찾으면, 복잡한 규칙 없이도 정확도가 향상될 것이다.
- **결과 (150개 샘플링 / 전수 테스트)**:
  - **정확도**: 65.33% / 63.17% (Baseline과 유사)
- **실패 원인 분석**:
  1.  **Rewriting의 한계**: 용어를 표준화해도 도메인 간 경계(GT) 자체가 모호한 문제는 해결되지 않음.
  2.  **LLM의 상식 vs GT**: "청약철회"는 상식적으로 "돈을 돌려받는 행위(제지급)"이지만 GT는 "계약해지"임. LLM은 상식을 따르려는 경향이 강함.

---

## 실험 8: Hybrid Workflow (Rule-based + LLM) - 초기 시도
- **날짜**: 2025-12-20
- **가설**: LLM이 지속적으로 헷갈리는 특정 키워드(청약철회 등)를 코드 레벨에서 강제로 라우팅하면 정확도가 올라갈 것이다.
- **결과 (150개 샘플링)**:
  - **정확도**: 59.33% (하락)
- **실패 원인**:
  1.  **규칙 매칭 실패**: 띄어쓰기 제어만으로는 다양한 질문 패턴을 커버하지 못함.
  2.  **프롬프트 공백**: 규칙으로 처리할 것이라 믿고 프롬프트에서 해당 가이드를 뺐는데, 규칙이 놓친 질문들이 LLM으로 넘어가서 오답이 됨.

---

## 실험 9: 정교한 Hybrid Workflow (Rule+Prompt 복원)
- **날짜**: 2025-12-20
- **가설**: 규칙을 더 정교하게 다듬고(확실한 것만 적용), 프롬프트도 실험 4 수준으로 상세하게 복원하면 상호 보완될 것이다.
- **결과 (150개 샘플링)**:
  - **정확도**: 66.67% (소폭 상승, 그러나 여전히 부족)
- **분석**:
  - 규칙은 작동하지만 전체 데이터셋의 복잡성을 커버하기엔 역부족.
  - 여전히 **도메인 간의 개념적 중첩**이 가장 큰 문제.

---

## 실험 10: "문서 그룹핑(Grouping)" 기반 사고 유도
- **날짜**: 2025-12-20 (예정)
- **가설**: 21개 도메인을 나열하는 대신, LLM이 이해하기 쉬운 **상위 개념(그룹)**으로 먼저 생각하게 한 뒤 세부 도메인을 선택하게 하면 혼동을 줄일 수 있을 것이다.
- **전략**:
  1.  **Thinking Process 부활 (Group-First)**: "이 질문은 [돈을 내는 것]인가, [계약을 바꾸는 것]인가?"를 먼저 판단하도록 유도.
  2.  **그룹 정의**:
      - **[자금 흐름]**: 보험료납입(내기) vs 제지급(받기) vs 대출(빌리기)
      - **[계약 상태 변경]**: 계약해지(끝내기) vs 계약정보(부활/감액 등 유지) vs 명의변경(사람 변경)
      - **[서류/증명]**: 증명서 안내장(발급) vs 각 도메인(단순 확인)
      - **[법/제도]**: 법 제도(일반 규정) vs 각 도메인(상품별 적용)
  3.  **Hybrid 유지**: `청약철회` 등 절대적인 키워드 규칙은 코드 레벨에서 유지.